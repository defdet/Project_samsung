{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "NlKqvou7_zhT"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pathlib import Path \n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from tensorflow.keras import layers\n",
        "import logging\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vFwSTEqAKFN",
        "outputId": "5ac1769c-0c76-4012-9d45-41aed68cf491"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(23242, 131)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset1 = pd.read_csv(\"FINAL_DATASET_1.csv\")\n",
        "dataset2 = pd.read_csv(\"FINAL_DATASET_2.csv\")\n",
        "dataset3 = pd.read_csv(\"FINAL_DATASET_3.csv\")\n",
        "dataset4 = pd.read_csv(\"FINAL_DATASET_4.csv\")\n",
        "dataset5 = pd.read_csv(\"FINAL_DATASET_5.csv\")\n",
        "dataset6 = pd.read_csv(\"FINAL_DATASET_6.csv\")\n",
        "dataset7 = pd.read_csv(\"FINAL_DATASET_7.csv\")\n",
        "dataset8 = pd.read_csv(\"FINAL_DATASET_8.csv\")\n",
        "dataset9 = pd.read_csv(\"FINAL_DATASET_9.csv\")\n",
        "dataset10 = pd.read_csv(\"FINAL_DATASET_10.csv\")\n",
        "dataset11 = pd.read_csv(\"FINAL_DATASET_11.csv\")\n",
        "dataset12 = pd.read_csv(\"FINAL_DATASET_12.csv\")\n",
        "dataset13 = pd.read_csv(\"FINAL_DATASET_13.csv\")\n",
        "dataset14 = pd.read_csv(\"FINAL_DATASET_14.csv\")\n",
        "dataset15 = pd.read_csv(\"FINAL_DATASET_15.csv\")\n",
        "dataset = pd.concat([dataset3, dataset4, dataset5, dataset6, dataset7, dataset8, dataset9, dataset10, dataset11, dataset13, dataset14])\n",
        "del dataset1\n",
        "del dataset2\n",
        "del dataset3\n",
        "del dataset4\n",
        "del dataset5\n",
        "del dataset6\n",
        "del dataset7\n",
        "del dataset8\n",
        "del dataset9\n",
        "del dataset10\n",
        "del dataset11\n",
        "del dataset12\n",
        "del dataset13\n",
        "del dataset14\n",
        "del dataset15\n",
        "dataset.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "yKBsER9diXHR"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'final_df' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[14], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m std \u001b[39m=\u001b[39m \u001b[39m0.1\u001b[39m\n\u001b[1;32m      3\u001b[0m augmented_data \u001b[39m=\u001b[39m []\n\u001b[0;32m----> 4\u001b[0m \u001b[39mfor\u001b[39;00m index, row \u001b[39min\u001b[39;00m final_df\u001b[39m.\u001b[39miterrows():\n\u001b[1;32m      5\u001b[0m     signal_data \u001b[39m=\u001b[39m row[:\u001b[39m128\u001b[39m]\u001b[39m.\u001b[39mvalues\n\u001b[1;32m      6\u001b[0m     non_zero_indices \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mnonzero(signal_data)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'final_df' is not defined"
          ]
        }
      ],
      "source": [
        "mean = 0 \n",
        "std = 0.1\n",
        "augmented_data = []\n",
        "for index, row in final_df.iterrows():\n",
        "    signal_data = row[:128].values\n",
        "    non_zero_indices = np.nonzero(signal_data)\n",
        "    noise = np.random.normal(mean, std, non_zero_indices[0].shape)\n",
        "    augmented_signal_data = signal_data.copy()\n",
        "    augmented_signal_data[non_zero_indices] += noise\n",
        "    new_row = np.concatenate([augmented_signal_data, row[128:].values])\n",
        "    augmented_data.append(new_row)\n",
        "augmented_df = pd.DataFrame(augmented_data, columns=final_df.columns)\n",
        "final_df = pd.concat([final_df, augmented_df], ignore_index=True)\n",
        "del augmented_df\n",
        "del augmented_data\n",
        "final_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pqcQPyFEpEv",
        "outputId": "d0670232-cc2d-48b2-e009-7642ac21e3bb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2699728, 131)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "min_scale = 0.8\n",
        "max_scale = 1.2\n",
        "augmented_data = []\n",
        "for index, row in final_df.iterrows():\n",
        "    signal_data = row[:128].values\n",
        "    non_zero_indices = np.nonzero(signal_data)\n",
        "    scale_factor = np.random.uniform(min_scale, max_scale)\n",
        "    augmented_signal_data = signal_data.copy()\n",
        "    augmented_signal_data[non_zero_indices] *= scale_factor\n",
        "    new_row = np.concatenate([augmented_signal_data, row[128:].values])\n",
        "    augmented_data.append(new_row)\n",
        "augmented_df = pd.DataFrame(augmented_data, columns=final_df.columns)\n",
        "final_df = pd.concat([final_df, augmented_df], ignore_index=True)\n",
        "del augmented_df\n",
        "del augmented_data\n",
        "final_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "max_shift = 30\n",
        "augmented_data = []\n",
        "for index, row in dataset.iterrows():\n",
        "    signal_data = row[:128].values\n",
        "    first_nonzero_idx = np.nonzero(signal_data)[0][0]\n",
        "    available_space = max_shift - first_nonzero_idx\n",
        "    for shift_amount in range(1, available_space + 1):\n",
        "        shifted_data = np.roll(signal_data, shift_amount)\n",
        "        new_row = np.concatenate([shifted_data, row[128:].values])\n",
        "        augmented_data.append(new_row)\n",
        "augmented_df = pd.DataFrame(augmented_data, columns=dataset.columns)\n",
        "del augmented_data\n",
        "final_df = pd.concat([dataset, augmented_df], ignore_index=True)\n",
        "del augmented_df\n",
        "del dataset\n",
        "final_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "i9cWw52kipjZ"
      },
      "outputs": [],
      "source": [
        "X = final_df.drop(columns = [\"x_position\", \"amp_threshold\", \"max_param\"])\n",
        "y = final_df[[\"x_position\"]]\n",
        "del final_df\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=37)\n",
        "X_train, X_test, y_train, y_test, X_val, y_val = pd.DataFrame(X_train).to_numpy(), pd.DataFrame(X_test).to_numpy(), pd.DataFrame(y_train).to_numpy(), pd.DataFrame(y_test).to_numpy(), pd.DataFrame(X_val).to_numpy(), pd.DataFrame(y_val).to_numpy()\n",
        "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
        "y_train = np.reshape(y_train, (y_train.shape[0], y_train.shape[1], 1))\n",
        "y_test = np.reshape(y_test, (y_test.shape[0], y_test.shape[1], 1))\n",
        "X_val = np.reshape(X_val, (X_val.shape[0], X_val.shape[1], 1))\n",
        "y_val = np.reshape(y_val, (y_val.shape[0], y_val.shape[1], 1))\n",
        "del X\n",
        "del y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "53995/53995 [==============================] - 303s 6ms/step - loss: 1402988.7500 - mae: 521.1533 - val_loss: 1329329.8750 - val_mae: 495.8930 - lr: 0.0100\n",
            "Epoch 2/100\n",
            "53995/53995 [==============================] - 302s 6ms/step - loss: 1329650.2500 - mae: 496.0300 - val_loss: 1328547.7500 - val_mae: 492.3795 - lr: 0.0100\n",
            "Epoch 3/100\n",
            "53995/53995 [==============================] - 322s 6ms/step - loss: 1329523.5000 - mae: 495.5900 - val_loss: 1328709.1250 - val_mae: 492.7889 - lr: 0.0100\n",
            "Epoch 4/100\n",
            "53995/53995 [==============================] - 313s 6ms/step - loss: 1329546.8750 - mae: 495.6167 - val_loss: 1328811.6250 - val_mae: 493.6137 - lr: 0.0100\n",
            "Epoch 5/100\n",
            "53995/53995 [==============================] - 307s 6ms/step - loss: 1329457.6250 - mae: 495.3103 - val_loss: 1329206.2500 - val_mae: 493.9182 - lr: 0.0100\n",
            "Epoch 6/100\n",
            "53995/53995 [==============================] - 312s 6ms/step - loss: 1328849.2500 - mae: 493.1632 - val_loss: 1329016.7500 - val_mae: 494.5500 - lr: 1.0000e-03\n",
            "Epoch 7/100\n",
            "53995/53995 [==============================] - 305s 6ms/step - loss: 1328848.1250 - mae: 493.1634 - val_loss: 1328973.2500 - val_mae: 493.2386 - lr: 1.0000e-03\n",
            "Epoch 8/100\n",
            "53995/53995 [==============================] - 305s 6ms/step - loss: 1328842.8750 - mae: 493.1682 - val_loss: 1328828.6250 - val_mae: 492.8977 - lr: 1.0000e-03\n",
            "Epoch 9/100\n",
            "53995/53995 [==============================] - 305s 6ms/step - loss: 1328773.7500 - mae: 492.9103 - val_loss: 1328726.6250 - val_mae: 492.7539 - lr: 1.0000e-04\n",
            "Epoch 10/100\n",
            "53995/53995 [==============================] - 304s 6ms/step - loss: 1328775.5000 - mae: 492.9123 - val_loss: 1328717.1250 - val_mae: 492.7586 - lr: 1.0000e-04\n",
            "Epoch 11/100\n",
            "38811/53995 [====================>.........] - ETA: 1:11 - loss: 1328879.5000 - mae: 492.9880"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[11], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m lr_schedule \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mcallbacks\u001b[39m.\u001b[39mReduceLROnPlateau(monitor\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m\"\u001b[39m, factor \u001b[39m=\u001b[39m \u001b[39m0.1\u001b[39m, patience \u001b[39m=\u001b[39m \u001b[39m3\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mGPU\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m---> 16\u001b[0m     history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(X_train, y_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m, validation_data \u001b[39m=\u001b[39;49m (X_test, y_test), verbose \u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m, callbacks \u001b[39m=\u001b[39;49m [lr_schedule])\n\u001b[1;32m     17\u001b[0m     loss \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mevaluate(X_val, y_val)\n\u001b[1;32m     18\u001b[0m     model\u001b[39m.\u001b[39msave(\u001b[39m\"\u001b[39m\u001b[39mmodel_june_new.h5\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/engine/training.py:1389\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1387\u001b[0m logs \u001b[39m=\u001b[39m tmp_logs  \u001b[39m# No error, now safe to assign to logs.\u001b[39;00m\n\u001b[1;32m   1388\u001b[0m end_step \u001b[39m=\u001b[39m step \u001b[39m+\u001b[39m data_handler\u001b[39m.\u001b[39mstep_increment\n\u001b[0;32m-> 1389\u001b[0m callbacks\u001b[39m.\u001b[39;49mon_train_batch_end(end_step, logs)\n\u001b[1;32m   1390\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstop_training:\n\u001b[1;32m   1391\u001b[0m   \u001b[39mbreak\u001b[39;00m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/callbacks.py:438\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[1;32m    432\u001b[0m \n\u001b[1;32m    433\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m    434\u001b[0m \u001b[39m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[1;32m    435\u001b[0m \u001b[39m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[1;32m    436\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    437\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[0;32m--> 438\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook(ModeKeys\u001b[39m.\u001b[39;49mTRAIN, \u001b[39m'\u001b[39;49m\u001b[39mend\u001b[39;49m\u001b[39m'\u001b[39;49m, batch, logs\u001b[39m=\u001b[39;49mlogs)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/callbacks.py:297\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    295\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[1;32m    296\u001b[0m \u001b[39melif\u001b[39;00m hook \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mend\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m--> 297\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_end_hook(mode, batch, logs)\n\u001b[1;32m    298\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    299\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    300\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mUnrecognized hook: \u001b[39m\u001b[39m{\u001b[39;00mhook\u001b[39m}\u001b[39;00m\u001b[39m. Expected values are [\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbegin\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mend\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m]\u001b[39m\u001b[39m'\u001b[39m)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/callbacks.py:318\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    315\u001b[0m   batch_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_start_time\n\u001b[1;32m    316\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_times\u001b[39m.\u001b[39mappend(batch_time)\n\u001b[0;32m--> 318\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook_helper(hook_name, batch, logs)\n\u001b[1;32m    320\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_times) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_batches_for_timing_check:\n\u001b[1;32m    321\u001b[0m   end_hook_name \u001b[39m=\u001b[39m hook_name\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/callbacks.py:356\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[39mfor\u001b[39;00m callback \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallbacks:\n\u001b[1;32m    355\u001b[0m   hook \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(callback, hook_name)\n\u001b[0;32m--> 356\u001b[0m   hook(batch, logs)\n\u001b[1;32m    358\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_timing:\n\u001b[1;32m    359\u001b[0m   \u001b[39mif\u001b[39;00m hook_name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_hook_times:\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/callbacks.py:1034\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1033\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mon_train_batch_end\u001b[39m(\u001b[39mself\u001b[39m, batch, logs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m-> 1034\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_update_progbar(batch, logs)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/callbacks.py:1106\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1102\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseen \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m add_seen\n\u001b[1;32m   1104\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1105\u001b[0m   \u001b[39m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[0;32m-> 1106\u001b[0m   logs \u001b[39m=\u001b[39m tf_utils\u001b[39m.\u001b[39;49msync_to_numpy_or_python_type(logs)\n\u001b[1;32m   1107\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprogbar\u001b[39m.\u001b[39mupdate(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseen, \u001b[39mlist\u001b[39m(logs\u001b[39m.\u001b[39mitems()), finalize\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/utils/tf_utils.py:563\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    560\u001b[0m     \u001b[39mreturn\u001b[39;00m t\n\u001b[1;32m    561\u001b[0m   \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mitem() \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mndim(t) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m t\n\u001b[0;32m--> 563\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49mnest\u001b[39m.\u001b[39;49mmap_structure(_to_single_numpy_or_python_type, tensors)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/util/nest.py:914\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    910\u001b[0m flat_structure \u001b[39m=\u001b[39m (flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[1;32m    911\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[1;32m    913\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 914\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[1;32m    915\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/util/nest.py:914\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    910\u001b[0m flat_structure \u001b[39m=\u001b[39m (flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[1;32m    911\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[1;32m    913\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 914\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39;49mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[1;32m    915\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/utils/tf_utils.py:557\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[1;32m    555\u001b[0m   \u001b[39m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[1;32m    556\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(t, tf\u001b[39m.\u001b[39mTensor):\n\u001b[0;32m--> 557\u001b[0m     t \u001b[39m=\u001b[39m t\u001b[39m.\u001b[39;49mnumpy()\n\u001b[1;32m    558\u001b[0m   \u001b[39m# Strings, ragged and sparse tensors don't have .item(). Return them as-is.\u001b[39;00m\n\u001b[1;32m    559\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(t, (np\u001b[39m.\u001b[39mndarray, np\u001b[39m.\u001b[39mgeneric)):\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:1223\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1200\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[1;32m   1201\u001b[0m \n\u001b[1;32m   1202\u001b[0m \u001b[39mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1220\u001b[0m \u001b[39m    NumPy dtype.\u001b[39;00m\n\u001b[1;32m   1221\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1222\u001b[0m \u001b[39m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[0;32m-> 1223\u001b[0m maybe_arr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1224\u001b[0m \u001b[39mreturn\u001b[39;00m maybe_arr\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(maybe_arr, np\u001b[39m.\u001b[39mndarray) \u001b[39melse\u001b[39;00m maybe_arr\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:1189\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1187\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_numpy\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m   1188\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1189\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy_internal()\n\u001b[1;32m   1190\u001b[0m   \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m     \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\n",
        "model = tf.keras.Sequential()\n",
        "model.add(layers.Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
        "model.add(layers.MaxPooling1D(pool_size=2))\n",
        "model.add(layers.Conv1D(filters=128, kernel_size=3, activation='relu'))\n",
        "model.add(layers.MaxPooling1D(pool_size=2))\n",
        "model.add(layers.Conv1D(filters=256, kernel_size=3, activation='relu'))\n",
        "model.add(layers.MaxPooling1D(pool_size=2))\n",
        "model.add(layers.Conv1D(filters=512, kernel_size=3, activation='relu'))\n",
        "model.add(layers.MaxPooling1D(pool_size=2))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(512, activation='relu'))\n",
        "model.add(layers.Dense(256, activation='relu'))\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate = 0.01)\n",
        "model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
        "lr_schedule = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor = 0.1, patience = 2)\n",
        "with tf.device(\"GPU\"):\n",
        "    history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data = (X_test, y_test), verbose = 1, callbacks = [lr_schedule])\n",
        "    loss = model.evaluate(X_val, y_val)\n",
        "    model.save(\"model_june_new.h5\")\n",
        "    print(\"EVALUATION\", loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "26105/26105 [==============================] - 148s 6ms/step - loss: 6357.9629 - mae: 60.3052 - val_loss: 6910.9370 - val_mae: 63.2117\n",
            "Epoch 2/100\n",
            "26105/26105 [==============================] - 147s 6ms/step - loss: 5856.7695 - mae: 58.3915 - val_loss: 6643.2085 - val_mae: 62.0940\n",
            "Epoch 3/100\n",
            "26105/26105 [==============================] - 145s 6ms/step - loss: 5630.7783 - mae: 57.4795 - val_loss: 6504.8130 - val_mae: 61.5976\n",
            "Epoch 4/100\n",
            "26105/26105 [==============================] - 148s 6ms/step - loss: 5488.0674 - mae: 56.8387 - val_loss: 6469.1763 - val_mae: 61.4441\n",
            "Epoch 5/100\n",
            "26105/26105 [==============================] - 148s 6ms/step - loss: 5370.2310 - mae: 56.3314 - val_loss: 6297.6982 - val_mae: 60.7835\n",
            "Epoch 6/100\n",
            "26105/26105 [==============================] - 149s 6ms/step - loss: 5271.6538 - mae: 55.8638 - val_loss: 6245.1670 - val_mae: 60.6116\n",
            "Epoch 7/100\n",
            "26105/26105 [==============================] - 150s 6ms/step - loss: 5187.3042 - mae: 55.4784 - val_loss: 6178.6196 - val_mae: 60.3609\n",
            "Epoch 8/100\n",
            "26105/26105 [==============================] - 149s 6ms/step - loss: 5114.1479 - mae: 55.1285 - val_loss: 6132.8291 - val_mae: 60.0308\n",
            "Epoch 9/100\n",
            "26105/26105 [==============================] - 149s 6ms/step - loss: 5048.0967 - mae: 54.8080 - val_loss: 6150.2798 - val_mae: 60.3287\n",
            "Epoch 10/100\n",
            "26105/26105 [==============================] - 148s 6ms/step - loss: 4988.4390 - mae: 54.5267 - val_loss: 6043.5391 - val_mae: 59.6036\n",
            "Epoch 11/100\n",
            "26105/26105 [==============================] - 151s 6ms/step - loss: 4932.8647 - mae: 54.2405 - val_loss: 5997.8853 - val_mae: 59.5417\n",
            "Epoch 12/100\n",
            "26105/26105 [==============================] - 149s 6ms/step - loss: 4881.3696 - mae: 54.0121 - val_loss: 5973.4287 - val_mae: 59.2437\n",
            "Epoch 13/100\n",
            "26105/26105 [==============================] - 150s 6ms/step - loss: 4835.3477 - mae: 53.7730 - val_loss: 6001.1353 - val_mae: 59.3690\n",
            "Epoch 14/100\n",
            "26105/26105 [==============================] - 150s 6ms/step - loss: 4789.8623 - mae: 53.5406 - val_loss: 5928.2354 - val_mae: 59.3190\n",
            "Epoch 15/100\n",
            "26105/26105 [==============================] - 151s 6ms/step - loss: 4749.3525 - mae: 53.3342 - val_loss: 5914.8994 - val_mae: 59.1081\n",
            "Epoch 16/100\n",
            "26105/26105 [==============================] - 150s 6ms/step - loss: 4711.0161 - mae: 53.1401 - val_loss: 5853.1211 - val_mae: 58.7678\n",
            "Epoch 17/100\n",
            "26105/26105 [==============================] - 151s 6ms/step - loss: 4673.3320 - mae: 52.9464 - val_loss: 5819.2510 - val_mae: 58.5849\n",
            "Epoch 18/100\n",
            "26105/26105 [==============================] - 151s 6ms/step - loss: 4640.3516 - mae: 52.7622 - val_loss: 5799.2061 - val_mae: 58.4720\n",
            "Epoch 19/100\n",
            "26105/26105 [==============================] - 151s 6ms/step - loss: 4606.9219 - mae: 52.5978 - val_loss: 5778.3735 - val_mae: 58.3656\n",
            "Epoch 20/100\n",
            "26105/26105 [==============================] - 154s 6ms/step - loss: 4575.2192 - mae: 52.4286 - val_loss: 5795.4648 - val_mae: 58.5161\n",
            "Epoch 21/100\n",
            "26105/26105 [==============================] - 149s 6ms/step - loss: 4545.5635 - mae: 52.2884 - val_loss: 5726.1934 - val_mae: 58.1839\n",
            "Epoch 22/100\n",
            "26105/26105 [==============================] - 150s 6ms/step - loss: 4513.9844 - mae: 52.1135 - val_loss: 5709.2114 - val_mae: 58.0475\n",
            "Epoch 23/100\n",
            "26105/26105 [==============================] - 150s 6ms/step - loss: 4487.1284 - mae: 51.9854 - val_loss: 5690.4048 - val_mae: 57.9160\n",
            "Epoch 24/100\n",
            "26105/26105 [==============================] - 150s 6ms/step - loss: 4459.1382 - mae: 51.8302 - val_loss: 5668.1479 - val_mae: 57.8232\n",
            "Epoch 25/100\n",
            "26105/26105 [==============================] - 151s 6ms/step - loss: 4435.0083 - mae: 51.7006 - val_loss: 5714.5283 - val_mae: 58.1005\n",
            "Epoch 26/100\n",
            "24919/26105 [===========================>..] - ETA: 5s - loss: 4407.9697 - mae: 51.5538"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[8], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mAdam(lr\u001b[39m=\u001b[39m\u001b[39m0.0001\u001b[39m), loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmse\u001b[39m\u001b[39m'\u001b[39m, metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mmae\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m      3\u001b[0m early_stopping \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mcallbacks\u001b[39m.\u001b[39mEarlyStopping(monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m, patience\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, restore_best_weights\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m----> 4\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train, y_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m, validation_data \u001b[39m=\u001b[39;49m (X_test, y_test), verbose \u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m, callbacks\u001b[39m=\u001b[39;49m[early_stopping])\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/engine/training.py:1384\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1377\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1378\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   1379\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   1380\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[1;32m   1381\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m   1382\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m   1383\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1384\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1385\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1386\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2953\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   2954\u001b[0m   (graph_function,\n\u001b[1;32m   2955\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2956\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   2957\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1849\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1850\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1851\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1852\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1853\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1854\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1855\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m     args,\n\u001b[1;32m   1857\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1858\u001b[0m     executing_eagerly)\n\u001b[1;32m   1859\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "model = keras.models.load_model(\"model_june_new9.h5\")\n",
        "history = model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.0001), loss='mse', metrics=['mae'])\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data = (X_test, y_test), verbose = 1, callbacks=[early_stopping])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "'NoneType' object is not subscriptable",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m plt\u001b[39m.\u001b[39mplot(history[\u001b[39m\"\u001b[39;49m\u001b[39mloss\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
          ]
        }
      ],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
